{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.26  Python-3.10.9 torch-1.11.0+cpu CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "0: 384x640 8 cars, 127.0ms\n",
      "Speed: 0.0ms pre-process, 127.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 9 cars, 139.5ms\n",
      "Speed: 2.8ms pre-process, 139.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 143.1ms\n",
      "Speed: 0.0ms pre-process, 143.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 2}\n",
      "[]\n",
      "{1186: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 cars, 101.4ms\n",
      "Speed: 0.0ms pre-process, 101.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 149.7ms\n",
      "Speed: 0.0ms pre-process, 149.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 4}\n",
      "[]\n",
      "{1186: 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 8 cars, 1 bus, 133.0ms\n",
      "Speed: 0.0ms pre-process, 133.0ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 7 cars, 100.0ms\n",
      "Speed: 0.0ms pre-process, 100.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5}\n",
      "[]\n",
      "{1186: 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 8 cars, 103.8ms\n",
      "Speed: 0.0ms pre-process, 103.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 120.3ms\n",
      "Speed: 0.0ms pre-process, 120.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5}\n",
      "[]\n",
      "{1186: 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 134.3ms\n",
      "Speed: 9.9ms pre-process, 134.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 158.8ms\n",
      "Speed: 0.0ms pre-process, 158.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5}\n",
      "[]\n",
      "{1186: 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 133.2ms\n",
      "Speed: 0.0ms pre-process, 133.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 137.5ms\n",
      "Speed: 0.0ms pre-process, 137.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 1}\n",
      "[]\n",
      "{1186: 5, 1193: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 134.6ms\n",
      "Speed: 0.0ms pre-process, 134.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 133.1ms\n",
      "Speed: 0.0ms pre-process, 133.1ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 1}\n",
      "[]\n",
      "{1186: 5, 1193: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 8 cars, 1 truck, 141.7ms\n",
      "Speed: 14.1ms pre-process, 141.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 151.0ms\n",
      "Speed: 0.0ms pre-process, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 2}\n",
      "[]\n",
      "{1186: 5, 1193: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 cars, 148.8ms\n",
      "Speed: 0.0ms pre-process, 148.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 97.1ms\n",
      "Speed: 0.0ms pre-process, 97.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 4}\n",
      "[]\n",
      "{1186: 5, 1193: 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 129.2ms\n",
      "Speed: 0.0ms pre-process, 129.2ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 137.1ms\n",
      "Speed: 0.0ms pre-process, 137.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 6}\n",
      "[]\n",
      "{1186: 5, 1193: 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 131.7ms\n",
      "Speed: 14.6ms pre-process, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 100.3ms\n",
      "Speed: 2.5ms pre-process, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 8}\n",
      "[]\n",
      "{1186: 5, 1193: 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 11 cars, 114.3ms\n",
      "Speed: 0.0ms pre-process, 114.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 127.9ms\n",
      "Speed: 0.0ms pre-process, 127.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 10}\n",
      "[]\n",
      "{1186: 5, 1193: 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 cars, 150.2ms\n",
      "Speed: 0.0ms pre-process, 150.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 136.8ms\n",
      "Speed: 13.5ms pre-process, 136.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 12}\n",
      "[]\n",
      "{1186: 5, 1193: 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 cars, 164.5ms\n",
      "Speed: 0.0ms pre-process, 164.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 145.2ms\n",
      "Speed: 7.1ms pre-process, 145.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 14}\n",
      "[]\n",
      "{1186: 5, 1193: 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 cars, 164.2ms\n",
      "Speed: 0.0ms pre-process, 164.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 142.1ms\n",
      "Speed: 0.0ms pre-process, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 16}\n",
      "[]\n",
      "{1186: 5, 1193: 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 cars, 2 trucks, 167.1ms\n",
      "Speed: 0.0ms pre-process, 167.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 155.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms pre-process, 155.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 99.9ms\n",
      "Speed: 0.0ms pre-process, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 160.9ms\n",
      "Speed: 0.0ms pre-process, 160.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 140.4ms\n",
      "Speed: 0.0ms pre-process, 140.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 21}\n",
      "[]\n",
      "{1186: 5, 1193: 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 1 truck, 152.2ms\n",
      "Speed: 0.0ms pre-process, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 152.0ms\n",
      "Speed: 0.0ms pre-process, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 23}\n",
      "[]\n",
      "{1186: 5, 1193: 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 149.9ms\n",
      "Speed: 0.0ms pre-process, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 140.0ms\n",
      "Speed: 2.7ms pre-process, 140.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 25}\n",
      "[]\n",
      "{1186: 5, 1193: 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 10 cars, 143.9ms\n",
      "Speed: 0.0ms pre-process, 143.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 124.3ms\n",
      "Speed: 9.7ms pre-process, 124.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 27}\n",
      "[]\n",
      "{1186: 5, 1193: 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 9 cars, 1 truck, 161.6ms\n",
      "Speed: 13.6ms pre-process, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 1 truck, 154.5ms\n",
      "Speed: 0.0ms pre-process, 154.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1186: 5, 1193: 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 1 truck, 142.1ms\n",
      "Speed: 11.5ms pre-process, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1193]\n",
      "{1186: 5, 1193: 31}\n"
     ]
    }
   ],
   "source": [
    "# from ultralytics import YOLO\n",
    "# from IPython.display import display, Image\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# # from object_detection import ObjectDetection\n",
    "# import math\n",
    "# from sort import *\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "def dist(P, A, B):\n",
    "    area = abs ( (A[0] - P[0]) * (B[1] - P[1]) - (A[1] - P[1]) * (B[0] - P[0]) )\n",
    "    AB = ( (A[0] - B[0]) ** 2 + (A[1] - B[1]) ** 2 ) ** 0.5\n",
    "    return ( area / AB )\n",
    "\n",
    "f1_A=(388,821)\n",
    "f1_B=(661,404) #distance 40\n",
    "\n",
    "f2_A=(582, 876) #id 194\n",
    "f2_B=(703, 415) #id 91 distance 30\n",
    "\n",
    "f3_A=(782, 865) #id 60\n",
    "f3_B=(743, 417) #id 30  distance 30\n",
    "\n",
    "f4_A=(999, 866) #id 105\n",
    "f4_B=(789, 417)  #id 85  distacne 30\n",
    "\n",
    "f5_A=(1183, 850) #id 4\n",
    "f5_B=(846, 429) #id 29 distance 30\n",
    "\n",
    "# Initialize Object Detection\n",
    "# od = ObjectDetection()\n",
    "model = YOLO('yolov8n.pt')\n",
    "cap = cv2.VideoCapture(\"los_angeles.mp4\")\n",
    "\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\t# 영상의 넓이(가로) 프레임\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\t# 영상의 높이(세로) 프레임\n",
    "frame_size = (frameWidth, frameHeight)\n",
    "\n",
    "print(frame_size)\n",
    "# Initialize count\n",
    "count = 0\n",
    "center_points_prev_frame = []\n",
    "\n",
    "danger_car_pt={}\n",
    "danger_car_id=[]\n",
    "tracking_objects = {}\n",
    "track_id = 0\n",
    "tracker = Sort(max_age=10, min_hits=3, iou_threshold=0.3)\n",
    "mask = cv2.imread(\"mask.png\")\n",
    "\n",
    "while True:\n",
    "    retval, frame = cap.read()\n",
    "    imgRegion = cv2.bitwise_and(frame,mask)\n",
    "    count += 1\n",
    "    if not(retval):\n",
    "        break\n",
    "\n",
    "    # Point current frame\n",
    "    center_points_cur_frame = []\n",
    "\n",
    "    # Detect objects on frame\n",
    "    results = model(imgRegion,stream=True)\n",
    "    detections = np.empty((0,5))\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cx = int((x1+x2) / 2)\n",
    "            cy = int((y1+y2) / 2)\n",
    "            center_points_cur_frame.append((cx, cy, 'Danger!'))\n",
    "            conf = math.ceil((box.conf[0]*100)) / 100\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    "            #print(\"FRAME N°\", count, \" \", x, y, w, h)\n",
    "            # cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "            if currentClass == \"car\" or currentClass == \"truck\" or currentClass == \"bus\" \\\n",
    "                    or currentClass == \"motorbike\" and conf > 0.3:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2,y2), (0, 255, 0), 2) \n",
    "                currentArray = np.array([x1,y1,x2,y2,conf])\n",
    "                detections = np.vstack((detections,currentArray))\n",
    "\n",
    "    # Only at the beginning we compare previous and current frame\n",
    "    \n",
    "\n",
    "    resultsTracker=tracker.update(detections)\n",
    "    \n",
    "    for result in resultsTracker:\n",
    "        x1,y1,x2,y2,Id = result\n",
    "        cx = int((x1+x2) / 2)\n",
    "        cy = int((y1+y2) / 2)\n",
    "        Id = int(Id)\n",
    "        # print(cx,cy,Id)\n",
    "                \n",
    "    # for object_id, pt in tracking_objects.items():\n",
    "        if dist((cx,cy), f1_A, f1_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'f1')\n",
    "        \n",
    "        elif dist((cx,cy), f2_A, f2_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'f2')\n",
    "            \n",
    "        elif dist((cx,cy), f3_A, f3_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'f3')\n",
    "        \n",
    "        elif dist((cx,cy), f4_A, f4_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'f4')\n",
    "        \n",
    "        elif dist((cx,cy), f5_A, f5_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'f5')\n",
    "        \n",
    "        else:\n",
    "            tracking_objects[Id]=(cx,cy,'Danger!')\n",
    "            if Id in danger_car_pt:\n",
    "                danger_car_pt[Id] +=1\n",
    "                if danger_car_pt[Id] > 30 and id not in danger_car_id:\n",
    "                    danger_car_id.append(Id)\n",
    "                    \n",
    "            else:\n",
    "                danger_car_pt[Id] = 1\n",
    "                \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "    for object_id, pt in tracking_objects.items():\n",
    "        tmp= pt[2]+'['+str(object_id)+']'\n",
    "        cv2.circle(frame, (pt[0],pt[1]), 5, (0, 0, 255), -1)\n",
    "        cv2.putText(frame, tmp, (pt[0], pt[1] - 7), 0, 0.8, (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "                \n",
    "    \n",
    "    \n",
    "\n",
    "    # print(\"Tracking objects\")\n",
    "    # # print(tracking_objects)\n",
    "\n",
    "\n",
    "    # print(\"CUR FRAME LEFT PTS\")\n",
    "    # print(center_points_cur_frame)\n",
    "    \n",
    "#     cv2.circle(frame, (1,1), 5, (0, 0, 255), -1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    # cv2.imshow(\"ImageFrame\",imgRegion)\n",
    "    # Make a copy of the points\n",
    "    center_points_prev_frame = center_points_cur_frame.copy()\n",
    "    print(danger_car_id)\n",
    "    print(danger_car_pt)\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from object_detection import ObjectDetection\n",
    "import math\n",
    "# from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.26  Python-3.10.9 torch-1.11.0+cpu CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 488)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "0: 352x640 2 persons, 9 cars, 4 buss, 169.4ms\n",
      "Speed: 1.6ms pre-process, 169.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 10 cars, 4 buss, 180.7ms\n",
      "Speed: 0.0ms pre-process, 180.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 9 cars, 5 buss, 172.7ms\n",
      "Speed: 1.0ms pre-process, 172.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 9 cars, 7 buss, 163.7ms\n",
      "Speed: 1.0ms pre-process, 163.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 9 cars, 7 buss, 159.7ms\n",
      "Speed: 1.0ms pre-process, 159.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 10 cars, 7 buss, 1 truck, 161.7ms\n",
      "Speed: 1.0ms pre-process, 161.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 10 cars, 6 buss, 156.5ms\n",
      "Speed: 0.9ms pre-process, 156.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 10 cars, 6 buss, 141.7ms\n",
      "Speed: 0.9ms pre-process, 141.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 10 cars, 6 buss, 156.5ms\n",
      "Speed: 1.0ms pre-process, 156.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 8 cars, 5 buss, 140.8ms\n",
      "Speed: 1.0ms pre-process, 140.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 9 cars, 6 buss, 159.1ms\n",
      "Speed: 1.0ms pre-process, 159.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 8 cars, 5 buss, 148.7ms\n",
      "Speed: 0.9ms pre-process, 148.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 5 cars, 6 buss, 150.9ms\n",
      "Speed: 0.0ms pre-process, 150.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 6 cars, 5 buss, 145.7ms\n",
      "Speed: 0.9ms pre-process, 145.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 6 cars, 4 buss, 165.4ms\n",
      "Speed: 0.9ms pre-process, 165.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 6 cars, 4 buss, 156.8ms\n",
      "Speed: 1.1ms pre-process, 156.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 6 cars, 4 buss, 139.7ms\n",
      "Speed: 0.9ms pre-process, 139.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 6 cars, 4 buss, 146.1ms\n",
      "Speed: 0.9ms pre-process, 146.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 8 cars, 5 buss, 175.9ms\n",
      "Speed: 1.0ms pre-process, 175.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 7 cars, 6 buss, 166.2ms\n",
      "Speed: 2.0ms pre-process, 166.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 8 cars, 5 buss, 169.9ms\n",
      "Speed: 0.9ms pre-process, 169.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 8 cars, 5 buss, 170.6ms\n",
      "Speed: 0.0ms pre-process, 170.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 10 cars, 7 buss, 150.9ms\n",
      "Speed: 1.0ms pre-process, 150.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 11 cars, 7 buss, 151.0ms\n",
      "Speed: 1.0ms pre-process, 151.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 9 cars, 6 buss, 153.7ms\n",
      "Speed: 1.0ms pre-process, 153.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 9 cars, 6 buss, 1 truck, 1 traffic light, 169.5ms\n",
      "Speed: 1.0ms pre-process, 169.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 9 cars, 6 buss, 1 truck, 1 traffic light, 208.5ms\n",
      "Speed: 1.0ms pre-process, 208.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 11 cars, 6 buss, 1 truck, 1 traffic light, 167.8ms\n",
      "Speed: 1.0ms pre-process, 167.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 14 cars, 2 buss, 1 truck, 1 traffic light, 168.1ms\n",
      "Speed: 1.1ms pre-process, 168.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 13 cars, 4 buss, 1 truck, 1 traffic light, 206.1ms\n",
      "Speed: 1.0ms pre-process, 206.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 15 cars, 4 buss, 1 traffic light, 181.3ms\n",
      "Speed: 1.1ms pre-process, 181.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 13 cars, 4 buss, 1 truck, 1 traffic light, 198.2ms\n",
      "Speed: 1.0ms pre-process, 198.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 13 cars, 2 buss, 1 truck, 1 traffic light, 195.2ms\n",
      "Speed: 2.0ms pre-process, 195.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 14 cars, 2 buss, 1 truck, 1 traffic light, 160.2ms\n",
      "Speed: 1.0ms pre-process, 160.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 13 cars, 3 buss, 1 truck, 1 traffic light, 151.3ms\n",
      "Speed: 1.0ms pre-process, 151.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 10 cars, 4 buss, 1 truck, 1 traffic light, 173.1ms\n",
      "Speed: 1.9ms pre-process, 173.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 11 cars, 5 buss, 1 truck, 183.0ms\n",
      "Speed: 1.0ms pre-process, 183.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 13 cars, 4 buss, 1 truck, 205.3ms\n",
      "Speed: 1.0ms pre-process, 205.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 14 cars, 4 buss, 1 truck, 198.5ms\n",
      "Speed: 1.0ms pre-process, 198.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 14 cars, 3 buss, 204.9ms\n",
      "Speed: 1.9ms pre-process, 204.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 10 cars, 5 buss, 202.3ms\n",
      "Speed: 2.0ms pre-process, 202.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 12 cars, 6 buss, 2 trucks, 209.0ms\n",
      "Speed: 1.0ms pre-process, 209.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 13 cars, 5 buss, 1 truck, 195.7ms\n",
      "Speed: 1.0ms pre-process, 195.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 9 cars, 4 buss, 2 trucks, 190.9ms\n",
      "Speed: 1.9ms pre-process, 190.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 11 cars, 3 buss, 1 truck, 199.1ms\n",
      "Speed: 1.0ms pre-process, 199.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 12 cars, 3 buss, 2 trucks, 184.9ms\n",
      "Speed: 1.0ms pre-process, 184.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 11 cars, 5 buss, 1 truck, 191.2ms\n",
      "Speed: 1.0ms pre-process, 191.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 8 cars, 5 buss, 2 trucks, 159.7ms\n",
      "Speed: 2.0ms pre-process, 159.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 11 cars, 6 buss, 1 truck, 161.6ms\n",
      "Speed: 1.0ms pre-process, 161.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 12 cars, 6 buss, 1 truck, 157.6ms\n",
      "Speed: 1.0ms pre-process, 157.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 12 cars, 5 buss, 1 truck, 201.4ms\n",
      "Speed: 1.0ms pre-process, 201.4ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 14 cars, 5 buss, 1 truck, 193.3ms\n",
      "Speed: 1.0ms pre-process, 193.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 12 cars, 4 buss, 1 truck, 154.0ms\n",
      "Speed: 1.0ms pre-process, 154.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 14 cars, 3 buss, 1 truck, 157.3ms\n",
      "Speed: 1.0ms pre-process, 157.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 16 cars, 3 buss, 2 trucks, 172.4ms\n",
      "Speed: 2.1ms pre-process, 172.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 13 cars, 4 buss, 2 trucks, 206.1ms\n",
      "Speed: 2.0ms pre-process, 206.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 14 cars, 3 buss, 1 truck, 198.3ms\n",
      "Speed: 2.0ms pre-process, 198.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 11 cars, 3 buss, 1 truck, 173.5ms\n",
      "Speed: 1.0ms pre-process, 173.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 11 cars, 5 buss, 1 truck, 157.7ms\n",
      "Speed: 1.0ms pre-process, 157.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 14 cars, 4 buss, 1 truck, 200.2ms\n",
      "Speed: 0.0ms pre-process, 200.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 12 cars, 5 buss, 161.8ms\n",
      "Speed: 1.0ms pre-process, 161.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 12 cars, 4 buss, 180.0ms\n",
      "Speed: 0.9ms pre-process, 180.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 15 cars, 4 buss, 145.1ms\n",
      "Speed: 1.0ms pre-process, 145.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 13 cars, 4 buss, 131.9ms\n",
      "Speed: 1.0ms pre-process, 131.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 12 cars, 3 buss, 1 truck, 151.0ms\n",
      "Speed: 1.0ms pre-process, 151.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 11 cars, 3 buss, 1 truck, 153.4ms\n",
      "Speed: 1.0ms pre-process, 153.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 12 cars, 3 buss, 1 truck, 138.4ms\n",
      "Speed: 1.1ms pre-process, 138.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 13 cars, 3 buss, 144.8ms\n",
      "Speed: 0.9ms pre-process, 144.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 13 cars, 3 buss, 1 truck, 151.3ms\n",
      "Speed: 0.0ms pre-process, 151.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 12 cars, 2 buss, 1 truck, 159.6ms\n",
      "Speed: 1.0ms pre-process, 159.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 persons, 12 cars, 2 buss, 1 truck, 133.3ms\n",
      "Speed: 1.0ms pre-process, 133.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# from ultralytics import YOLO\n",
    "# from IPython.display import display, Image\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# # from object_detection import ObjectDetection\n",
    "# import math\n",
    "# from sort import *\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "def dist(P, A, B):\n",
    "    area = abs ( (A[0] - P[0]) * (B[1] - P[1]) - (A[1] - P[1]) * (B[0] - P[0]) )\n",
    "    AB = ( (A[0] - B[0]) ** 2 + (A[1] - B[1]) ** 2 ) ** 0.5\n",
    "    return ( area / AB )\n",
    "\n",
    "f1_A=(388,821)\n",
    "f1_B=(661,404) #distance 40\n",
    "\n",
    "f2_A=(582, 876) #id 194\n",
    "f2_B=(703, 415) #id 91 distance 30\n",
    "\n",
    "f3_A=(782, 865) #id 60\n",
    "f3_B=(743, 417) #id 30  distance 30\n",
    "\n",
    "f4_A=(999, 866) #id 105\n",
    "f4_B=(789, 417)  #id 85  distacne 30\n",
    "\n",
    "f5_A=(1183, 850) #id 4\n",
    "f5_B=(846, 429) #id 29 distance 30\n",
    "\n",
    "# Initialize Object Detection\n",
    "# od = ObjectDetection()\n",
    "model = YOLO('yolov8n.pt')\n",
    "cap = cv2.VideoCapture(\"2.mp4\")\n",
    "\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\t# 영상의 넓이(가로) 프레임\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\t# 영상의 높이(세로) 프레임\n",
    "frame_size = (frameWidth, frameHeight)\n",
    "\n",
    "print(frame_size)\n",
    "# Initialize count\n",
    "count = 0\n",
    "center_points_prev_frame = []\n",
    "\n",
    "danger_car_id=[]\n",
    "\n",
    "tracking_objects = {}\n",
    "track_id = 0\n",
    "\n",
    "tracker = Sort(max_age=10, min_hits=3, iou_threshold=0.3)\n",
    "mask = cv2.imread(\"mask.png\")\n",
    "\n",
    "while True:\n",
    "    retval, frame = cap.read()\n",
    "    # imgRegion = cv2.bitwise_and(frame,mask)\n",
    "    count += 1\n",
    "    if not(retval):\n",
    "        break\n",
    "\n",
    "    # Point current frame\n",
    "    center_points_cur_frame = []\n",
    "\n",
    "    # Detect objects on frame\n",
    "    results = model(frame,stream=True)\n",
    "    detections = np.empty((0,5))\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cx = int((x1+x2) / 2)\n",
    "            cy = int((y1+y2) / 2)\n",
    "            center_points_cur_frame.append((cx, cy, 'Danger!'))\n",
    "            conf = math.ceil((box.conf[0]*100)) / 100\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    "            #print(\"FRAME N°\", count, \" \", x, y, w, h)\n",
    "            # cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "            if currentClass == \"car\" or currentClass == \"truck\" or currentClass == \"bus\" \\\n",
    "                    or currentClass == \"motorbike\" or currentClass == \"person\" and conf > 0.3:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2,y2), (0, 255, 0), 2) \n",
    "                currentArray = np.array([x1,y1,x2,y2,conf])\n",
    "                detections = np.vstack((detections,currentArray))\n",
    "\n",
    "    # Only at the beginning we compare previous and current frame\n",
    "    \n",
    "\n",
    "    resultsTracker=tracker.update(detections)\n",
    "    \n",
    "    for result in resultsTracker:\n",
    "        x1,y1,x2,y2,Id = result\n",
    "        cx = int((x1+x2) / 2)\n",
    "        cy = int((y1+y2) / 2)\n",
    "        Id = int(Id)\n",
    "        # print(cx,cy,Id)\n",
    "                \n",
    "    # for object_id, pt in tracking_objects.items():\n",
    "        # if dist((cx,cy), f1_A, f1_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f1')\n",
    "        \n",
    "        # elif dist((cx,cy), f2_A, f2_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f2')\n",
    "            \n",
    "        # elif dist((cx,cy), f3_A, f3_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f3')\n",
    "        \n",
    "        # elif dist((cx,cy), f4_A, f4_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f4')\n",
    "        \n",
    "        # elif dist((cx,cy), f5_A, f5_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f5')\n",
    "        \n",
    "        # else:\n",
    "        #     tracking_objects[Id]=(cx,cy,'Danger!')\n",
    "        \n",
    "            \n",
    "            \n",
    "    # for object_id, pt in tracking_objects.items():\n",
    "    #     tmp= pt[2]+'['+str(object_id)+']'\n",
    "    #     cv2.circle(frame, (pt[0],pt[1]), 5, (0, 0, 255), -1)\n",
    "    #     cv2.putText(frame, tmp, (pt[0], pt[1] - 7), 0, 0.8, (0, 0, 255), 2)\n",
    "        \n",
    "    #     if (pt[2]=='Danger!'):\n",
    "    #         danger_car_id.append(object_id)\n",
    "            \n",
    "                \n",
    "    \n",
    "    \n",
    "\n",
    "    # print(\"Tracking objects\")\n",
    "    # # print(tracking_objects)\n",
    "\n",
    "\n",
    "    # print(\"CUR FRAME LEFT PTS\")\n",
    "    # print(center_points_cur_frame)\n",
    "    \n",
    "#     cv2.circle(frame, (1,1), 5, (0, 0, 255), -1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    # cv2.imshow(\"ImageFrame\",imgRegion)\n",
    "    # Make a copy of the points\n",
    "    center_points_prev_frame = center_points_cur_frame.copy()\n",
    "\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
