{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 488)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 8 cars, 2 buss, 65.4ms\n",
      "Speed: 3.0ms preprocess, 65.4ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 1, 382: 1, 381: 1, 380: 1, 379: 1, 378: 1, 377: 1, 376: 1, 375: 1, 374: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 9 cars, 2 buss, 97.9ms\n",
      "Speed: 6.0ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 2, 382: 2, 381: 2, 380: 2, 379: 2, 378: 2, 377: 2, 376: 2, 375: 2, 374: 2, 384: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 9 cars, 2 buss, 93.7ms\n",
      "Speed: 5.0ms preprocess, 93.7ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 10 cars, 2 buss, 62.2ms\n",
      "Speed: 2.2ms preprocess, 62.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 8 cars, 2 buss, 56.9ms\n",
      "Speed: 2.0ms preprocess, 56.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 3, 382: 3, 381: 3, 380: 3, 379: 3, 378: 3, 377: 3, 376: 3, 375: 3, 374: 3, 384: 1}\n",
      "[]\n",
      "{383: 4, 382: 4, 381: 4, 380: 4, 379: 4, 378: 4, 377: 4, 376: 4, 375: 4, 374: 4, 384: 2}\n",
      "[]\n",
      "{383: 5, 382: 5, 381: 5, 380: 5, 379: 5, 378: 5, 377: 5, 376: 5, 375: 5, 374: 5, 384: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 9 cars, 1 bus, 56.6ms\n",
      "Speed: 1.0ms preprocess, 56.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 8 cars, 1 bus, 63.7ms\n",
      "Speed: 1.1ms preprocess, 63.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 9 cars, 1 bus, 64.0ms\n",
      "Speed: 1.0ms preprocess, 64.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 6, 382: 5, 381: 6, 380: 6, 379: 6, 378: 6, 377: 6, 376: 6, 375: 6, 374: 6, 384: 2}\n",
      "[]\n",
      "{383: 7, 382: 5, 381: 7, 380: 7, 379: 7, 378: 7, 377: 7, 376: 7, 375: 7, 374: 7, 384: 2}\n",
      "[]\n",
      "{383: 8, 382: 5, 381: 8, 380: 8, 379: 8, 378: 8, 377: 8, 376: 8, 375: 8, 374: 8, 384: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 11 cars, 1 bus, 56.8ms\n",
      "Speed: 2.1ms preprocess, 56.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 11 cars, 1 bus, 64.5ms\n",
      "Speed: 1.1ms preprocess, 64.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 11 cars, 1 bus, 62.5ms\n",
      "Speed: 2.1ms preprocess, 62.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 9, 382: 5, 381: 9, 380: 9, 379: 9, 378: 9, 377: 9, 376: 9, 375: 9, 374: 9, 384: 3}\n",
      "[]\n",
      "{383: 10, 382: 5, 381: 10, 380: 10, 379: 10, 378: 10, 377: 10, 376: 10, 375: 10, 374: 10, 384: 4, 386: 1, 385: 1}\n",
      "[]\n",
      "{383: 11, 382: 5, 381: 11, 380: 11, 379: 11, 378: 11, 377: 11, 376: 11, 375: 11, 374: 11, 384: 5, 386: 2, 385: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 10 cars, 1 bus, 62.2ms\n",
      "Speed: 2.0ms preprocess, 62.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 9 cars, 1 bus, 60.4ms\n",
      "Speed: 2.2ms preprocess, 60.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 10 cars, 1 bus, 65.8ms\n",
      "Speed: 1.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 12, 382: 5, 381: 12, 380: 12, 379: 12, 378: 12, 377: 12, 376: 12, 375: 12, 374: 12, 384: 6, 386: 3, 385: 2}\n",
      "[]\n",
      "{383: 13, 382: 5, 381: 13, 380: 13, 379: 12, 378: 13, 377: 13, 376: 12, 375: 13, 374: 13, 384: 7, 386: 4, 385: 2}\n",
      "[]\n",
      "{383: 14, 382: 5, 381: 14, 380: 14, 379: 12, 378: 14, 377: 13, 376: 12, 375: 14, 374: 14, 384: 8, 386: 5, 385: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 10 cars, 1 bus, 61.8ms\n",
      "Speed: 2.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 9 cars, 1 bus, 69.5ms\n",
      "Speed: 1.0ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 10 cars, 1 bus, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 15, 382: 5, 381: 15, 380: 15, 379: 12, 378: 15, 377: 13, 376: 12, 375: 15, 374: 15, 384: 9, 386: 6, 385: 2}\n",
      "[]\n",
      "{383: 16, 382: 5, 381: 16, 380: 16, 379: 12, 378: 16, 377: 13, 376: 12, 375: 16, 374: 16, 384: 9, 386: 7, 385: 2}\n",
      "[]\n",
      "{383: 17, 382: 5, 381: 17, 380: 17, 379: 12, 378: 17, 377: 13, 376: 13, 375: 17, 374: 17, 384: 9, 386: 8, 385: 2, 388: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 9 cars, 1 bus, 62.3ms\n",
      "Speed: 2.0ms preprocess, 62.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 9 cars, 1 bus, 64.5ms\n",
      "Speed: 2.0ms preprocess, 64.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 9 cars, 1 bus, 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 18, 382: 5, 381: 18, 380: 18, 379: 12, 378: 18, 377: 13, 376: 14, 375: 18, 374: 18, 384: 9, 386: 9, 385: 2, 388: 2, 389: 1}\n",
      "[]\n",
      "{383: 19, 382: 5, 381: 19, 380: 19, 379: 12, 378: 18, 377: 13, 376: 15, 375: 19, 374: 19, 384: 9, 386: 9, 385: 2, 388: 3, 389: 2}\n",
      "[]\n",
      "{383: 20, 382: 5, 381: 20, 380: 20, 379: 12, 378: 18, 377: 14, 376: 16, 375: 20, 374: 20, 384: 10, 386: 9, 385: 2, 388: 4, 389: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 8 cars, 1 bus, 64.6ms\n",
      "Speed: 2.0ms preprocess, 64.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 7 cars, 1 bus, 58.7ms\n",
      "Speed: 2.2ms preprocess, 58.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 7 cars, 1 bus, 55.5ms\n",
      "Speed: 1.0ms preprocess, 55.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 21, 382: 5, 381: 21, 380: 21, 379: 12, 378: 18, 377: 15, 376: 17, 375: 21, 374: 21, 384: 11, 386: 9, 385: 2, 388: 5, 389: 3}\n",
      "[]\n",
      "{383: 21, 382: 5, 381: 22, 380: 22, 379: 12, 378: 18, 377: 16, 376: 18, 375: 22, 374: 22, 384: 12, 386: 9, 385: 2, 388: 6, 389: 3}\n",
      "[]\n",
      "{383: 21, 382: 5, 381: 23, 380: 23, 379: 12, 378: 18, 377: 17, 376: 19, 375: 23, 374: 23, 384: 13, 386: 9, 385: 2, 388: 7, 389: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 7 cars, 1 bus, 64.5ms\n",
      "Speed: 1.0ms preprocess, 64.5ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 6 cars, 3 buss, 1 truck, 61.6ms\n",
      "Speed: 1.0ms preprocess, 61.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 6 cars, 3 buss, 1 truck, 81.5ms\n",
      "Speed: 2.3ms preprocess, 81.5ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 21, 382: 5, 381: 24, 380: 24, 379: 12, 378: 18, 377: 18, 376: 20, 375: 24, 374: 24, 384: 14, 386: 9, 385: 2, 388: 8, 389: 3}\n",
      "[]\n",
      "{383: 21, 382: 5, 381: 25, 380: 24, 379: 12, 378: 18, 377: 19, 376: 21, 375: 25, 374: 25, 384: 14, 386: 9, 385: 2, 388: 9, 389: 3}\n",
      "[]\n",
      "{383: 21, 382: 5, 381: 26, 380: 24, 379: 12, 378: 18, 377: 20, 376: 22, 375: 26, 374: 26, 384: 14, 386: 9, 385: 2, 388: 10, 389: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 6 cars, 2 buss, 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 6 cars, 2 buss, 65.1ms\n",
      "Speed: 1.4ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 7 cars, 3 buss, 1 truck, 53.0ms\n",
      "Speed: 1.1ms preprocess, 53.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 21, 382: 5, 381: 27, 380: 24, 379: 12, 378: 18, 377: 21, 376: 23, 375: 27, 374: 27, 384: 14, 386: 9, 385: 2, 388: 11, 389: 3, 394: 1, 392: 1}\n",
      "[]\n",
      "{383: 21, 382: 5, 381: 28, 380: 24, 379: 12, 378: 18, 377: 22, 376: 24, 375: 28, 374: 28, 384: 14, 386: 9, 385: 2, 388: 12, 389: 3, 394: 2, 392: 2}\n",
      "[]\n",
      "{383: 21, 382: 5, 381: 29, 380: 24, 379: 12, 378: 18, 377: 23, 376: 25, 375: 29, 374: 29, 384: 14, 386: 9, 385: 2, 388: 13, 389: 3, 394: 3, 392: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 6 cars, 3 buss, 1 truck, 63.3ms\n",
      "Speed: 2.0ms preprocess, 63.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 7 cars, 3 buss, 1 truck, 57.6ms\n",
      "Speed: 2.5ms preprocess, 57.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 8 cars, 3 buss, 1 truck, 63.6ms\n",
      "Speed: 1.5ms preprocess, 63.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{383: 21, 382: 5, 381: 30, 380: 24, 379: 12, 378: 18, 377: 24, 376: 26, 375: 30, 374: 29, 384: 14, 386: 9, 385: 2, 388: 14, 389: 3, 394: 4, 392: 4}\n",
      "[381, 375]\n",
      "{383: 21, 382: 5, 381: 31, 380: 24, 379: 12, 378: 18, 377: 25, 376: 27, 375: 31, 374: 29, 384: 14, 386: 9, 385: 2, 388: 15, 389: 3, 394: 5, 392: 5, 396: 1}\n",
      "[381, 375, 381, 375]\n",
      "{383: 21, 382: 5, 381: 32, 380: 24, 379: 12, 378: 18, 377: 26, 376: 28, 375: 32, 374: 29, 384: 14, 386: 9, 385: 2, 388: 16, 389: 3, 394: 6, 392: 6, 396: 2, 398: 1, 397: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 9 cars, 2 buss, 1 truck, 57.8ms\n",
      "Speed: 1.0ms preprocess, 57.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 7 cars, 3 buss, 47.2ms\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 8 cars, 2 buss, 62.9ms\n",
      "Speed: 1.4ms preprocess, 62.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375]\n",
      "{383: 21, 382: 5, 381: 33, 380: 24, 379: 12, 378: 18, 377: 26, 376: 29, 375: 33, 374: 29, 384: 14, 386: 9, 385: 2, 388: 17, 389: 3, 394: 7, 392: 6, 396: 3, 398: 2, 397: 2, 399: 1}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375]\n",
      "{383: 21, 382: 5, 381: 34, 380: 24, 379: 12, 378: 18, 377: 26, 376: 30, 375: 34, 374: 30, 384: 14, 386: 9, 385: 2, 388: 18, 389: 3, 394: 7, 392: 6, 396: 4, 398: 3, 397: 3, 399: 2}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 34, 380: 24, 379: 12, 378: 18, 377: 26, 376: 31, 375: 35, 374: 31, 384: 14, 386: 9, 385: 2, 388: 19, 389: 3, 394: 7, 392: 7, 396: 5, 398: 3, 397: 4, 399: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 13 cars, 2 buss, 1 truck, 58.8ms\n",
      "Speed: 1.0ms preprocess, 58.8ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 12 cars, 2 buss, 1 truck, 61.2ms\n",
      "Speed: 2.0ms preprocess, 61.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 12 cars, 2 buss, 1 truck, 56.3ms\n",
      "Speed: 1.0ms preprocess, 56.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 34, 380: 24, 379: 12, 378: 18, 377: 26, 376: 32, 375: 36, 374: 32, 384: 14, 386: 10, 385: 2, 388: 20, 389: 3, 394: 7, 392: 8, 396: 6, 398: 3, 397: 5, 399: 2, 400: 1}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 35, 380: 24, 379: 12, 378: 18, 377: 26, 376: 33, 375: 37, 374: 33, 384: 15, 386: 11, 385: 2, 388: 21, 389: 3, 394: 7, 392: 9, 396: 7, 398: 4, 397: 6, 399: 2, 400: 2}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 36, 380: 24, 379: 12, 378: 18, 377: 26, 376: 34, 375: 38, 374: 34, 384: 16, 386: 12, 385: 2, 388: 22, 389: 3, 394: 7, 392: 10, 396: 8, 398: 4, 397: 6, 399: 2, 400: 3, 402: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 12 cars, 1 bus, 1 truck, 56.3ms\n",
      "Speed: 1.0ms preprocess, 56.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 9 cars, 1 bus, 2 trucks, 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 10 cars, 1 bus, 2 trucks, 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 37, 380: 24, 379: 12, 378: 18, 377: 26, 376: 35, 375: 39, 374: 35, 384: 16, 386: 13, 385: 2, 388: 23, 389: 3, 394: 7, 392: 11, 396: 9, 398: 4, 397: 6, 399: 2, 400: 3, 402: 2}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 38, 380: 24, 379: 12, 378: 18, 377: 26, 376: 36, 375: 40, 374: 36, 384: 16, 386: 13, 385: 2, 388: 24, 389: 3, 394: 7, 392: 12, 396: 10, 398: 4, 397: 6, 399: 2, 400: 3, 402: 2, 405: 1, 404: 1}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 39, 380: 24, 379: 12, 378: 18, 377: 26, 376: 37, 375: 41, 374: 37, 384: 16, 386: 13, 385: 2, 388: 25, 389: 3, 394: 7, 392: 13, 396: 11, 398: 4, 397: 6, 399: 2, 400: 3, 402: 2, 405: 2, 404: 2, 401: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 9 cars, 2 buss, 2 trucks, 58.8ms\n",
      "Speed: 0.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 9 cars, 2 buss, 2 trucks, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 9 cars, 3 buss, 2 trucks, 55.3ms\n",
      "Speed: 2.3ms preprocess, 55.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374]\n",
      "{383: 21, 382: 5, 381: 40, 380: 24, 379: 12, 378: 18, 377: 26, 376: 37, 375: 42, 374: 38, 384: 16, 386: 13, 385: 2, 388: 26, 389: 3, 394: 7, 392: 14, 396: 12, 398: 4, 397: 6, 399: 2, 400: 3, 402: 2, 405: 3, 404: 2, 401: 2, 407: 1, 406: 1}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374]\n",
      "{383: 21, 382: 5, 381: 41, 380: 24, 379: 12, 378: 18, 377: 26, 376: 37, 375: 43, 374: 39, 384: 16, 386: 13, 385: 2, 388: 27, 389: 3, 394: 7, 392: 15, 396: 13, 398: 4, 397: 6, 399: 2, 400: 3, 402: 2, 405: 4, 404: 2, 401: 3, 407: 2, 406: 1}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374, 376, 375, 374]\n",
      "{383: 21, 382: 5, 381: 41, 380: 24, 379: 12, 378: 18, 377: 26, 376: 38, 375: 44, 374: 40, 384: 16, 386: 14, 385: 2, 388: 28, 389: 3, 394: 7, 392: 16, 396: 14, 398: 4, 397: 6, 399: 2, 400: 3, 402: 2, 405: 5, 404: 2, 401: 4, 407: 3, 406: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 11 cars, 1 bus, 2 trucks, 67.4ms\n",
      "Speed: 2.0ms preprocess, 67.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 10 cars, 1 bus, 2 trucks, 67.4ms\n",
      "Speed: 2.0ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 person, 13 cars, 2 buss, 2 trucks, 52.3ms\n",
      "Speed: 2.0ms preprocess, 52.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374, 376, 375, 374, 376, 375]\n",
      "{383: 21, 382: 5, 381: 41, 380: 24, 379: 12, 378: 18, 377: 26, 376: 39, 375: 45, 374: 40, 384: 16, 386: 15, 385: 2, 388: 29, 389: 3, 394: 7, 392: 17, 396: 15, 398: 4, 397: 7, 399: 2, 400: 3, 402: 2, 405: 6, 404: 2, 401: 5, 407: 4, 406: 1}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374, 376, 375, 374, 376, 375, 381, 376, 375]\n",
      "{383: 21, 382: 5, 381: 42, 380: 24, 379: 12, 378: 18, 377: 26, 376: 40, 375: 46, 374: 40, 384: 16, 386: 15, 385: 2, 388: 30, 389: 3, 394: 7, 392: 18, 396: 16, 398: 4, 397: 7, 399: 2, 400: 3, 402: 2, 405: 7, 404: 2, 401: 6, 407: 5, 406: 2, 408: 1}\n",
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374, 376, 375, 374, 376, 375, 381, 376, 375, 388, 381, 376, 375]\n",
      "{383: 21, 382: 5, 381: 43, 380: 24, 379: 12, 378: 18, 377: 26, 376: 41, 375: 47, 374: 40, 384: 16, 386: 15, 385: 2, 388: 31, 389: 3, 394: 7, 392: 19, 396: 17, 398: 4, 397: 7, 399: 2, 400: 3, 402: 2, 405: 8, 404: 2, 401: 7, 407: 6, 406: 3, 408: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 13 cars, 2 buss, 2 trucks, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 2.5ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374, 376, 375, 374, 376, 375, 381, 376, 375, 388, 381, 376, 375, 388, 381, 375]\n",
      "{383: 21, 382: 5, 381: 44, 380: 24, 379: 12, 378: 18, 377: 26, 376: 41, 375: 48, 374: 40, 384: 17, 386: 16, 385: 2, 388: 32, 389: 3, 394: 7, 392: 20, 396: 18, 398: 4, 397: 8, 399: 2, 400: 3, 402: 3, 405: 9, 404: 2, 401: 8, 407: 7, 406: 4, 408: 3, 410: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 11 cars, 2 buss, 1 truck, 100.4ms\n",
      "Speed: 5.6ms preprocess, 100.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374, 376, 375, 374, 376, 375, 381, 376, 375, 388, 381, 376, 375, 388, 381, 375, 388, 375]\n",
      "{383: 21, 382: 5, 381: 44, 380: 24, 379: 12, 378: 18, 377: 26, 376: 41, 375: 49, 374: 40, 384: 18, 386: 17, 385: 2, 388: 33, 389: 3, 394: 7, 392: 21, 396: 19, 398: 4, 397: 9, 399: 2, 400: 3, 402: 4, 405: 10, 404: 2, 401: 8, 407: 7, 406: 5, 408: 4, 410: 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 10 cars, 2 buss, 2 trucks, 107.0ms\n",
      "Speed: 5.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381, 375, 381, 375, 381, 375, 381, 375, 376, 375, 374, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 376, 375, 374, 381, 375, 374, 381, 375, 374, 376, 375, 374, 376, 375, 381, 376, 375, 388, 381, 376, 375, 388, 381, 375, 388, 375, 388, 375]\n",
      "{383: 21, 382: 5, 381: 44, 380: 24, 379: 12, 378: 18, 377: 26, 376: 41, 375: 50, 374: 40, 384: 19, 386: 18, 385: 2, 388: 34, 389: 3, 394: 7, 392: 22, 396: 20, 398: 4, 397: 10, 399: 2, 400: 3, 402: 5, 405: 11, 404: 2, 401: 8, 407: 7, 406: 6, 408: 5, 410: 2}\n"
     ]
    }
   ],
   "source": [
    "#from ultralytics import YOLO\n",
    "#from IPython.display import display, Image\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "#from object_detection import ObjectDetection\n",
    "#import math\n",
    "#from sort import *\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\"]\n",
    "\n",
    "def dist(P, A, B):\n",
    "    area = abs ( (A[0] - P[0]) * (B[1] - P[1]) - (A[1] - P[1]) * (B[0] - P[0]) )\n",
    "    AB = ( (A[0] - B[0]) ** 2 + (A[1] - B[1]) ** 2 ) ** 0.5\n",
    "    return ( area / AB )\n",
    "\n",
    "L1_A=(734,337)\n",
    "L1_B=(455,740) #distance 40\n",
    "\n",
    "L2_A=(819,334) #id 194\n",
    "L2_B=(573,743) #id 91 distance 30\n",
    "\n",
    "L3_A=(898,337) #id 60\n",
    "L3_B=(675,747) #id 30  distance 30\n",
    "\n",
    "L4_A=(973,340) #id 105\n",
    "L4_B=(786,743)  #id 85  distacne 30\n",
    "\n",
    "\n",
    "R1_A=(1117,321)\n",
    "R1_B=(976,822) #distance 40\n",
    "\n",
    "R2_A=(7793,317) #id 194\n",
    "R2_B=(1104,819) #id 91 distance 30\n",
    "\n",
    "R3_A=(1288,321) #id 60\n",
    "R3_B=(1235,806) #id 30  distance 30\n",
    "\n",
    "R4_A=(1380,327) #id 105\n",
    "R4_B=(1367,806)  #id 85  distacne 30\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Object Detection\n",
    "# od = ObjectDetection()\n",
    "model = YOLO('yolov8n.pt')\n",
    "cap = cv2.VideoCapture(\"Tokyo1.mp4\")\n",
    "\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\t# 영상의 넓이(가로) 프레임\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\t# 영상의 높이(세로) 프레임\n",
    "frame_size = (frameWidth, frameHeight)\n",
    "\n",
    "print(frame_size)\n",
    "# Initialize count\n",
    "count = 0\n",
    "center_points_prev_frame = []\n",
    "\n",
    "danger_car_pt={}\n",
    "danger_car_id=[]\n",
    "tracking_objects = {}\n",
    "track_id = 0\n",
    "tracker = Sort(max_age=12, min_hits=2, iou_threshold=0.4)\n",
    "\n",
    "mask = cv2.imread(\"mmask.png\")\n",
    "mask=cv2.resize(mask,(frameWidth,frameHeight))\n",
    "\n",
    "while True:\n",
    "    retval, frame = cap.read()\n",
    "    imgRegion = cv2.bitwise_and(frame,mask)\n",
    "    count += 1\n",
    "    if not(retval):\n",
    "        break\n",
    "\n",
    "    # Point current frame\n",
    "    center_points_cur_frame = []\n",
    "\n",
    "    # Detect objects on frame\n",
    "    results = model(imgRegion,stream=True)\n",
    "    detections = np.empty((0,5))\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cx = int((x1+x2) / 2)\n",
    "            cy = int((y1+y2) / 2)\n",
    "            center_points_cur_frame.append((cx, cy, 'Danger!'))\n",
    "            conf = math.ceil((box.conf[0]*100)) / 100\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    "\n",
    "            if currentClass == \"car\" or currentClass == \"truck\" or currentClass == \"bus\" \\\n",
    "                    or currentClass == \"motorbike\" and conf > 0.3:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2,y2), (0, 255, 0), 2) \n",
    "                currentArray = np.array([x1,y1,x2,y2,conf])\n",
    "                detections = np.vstack((detections,currentArray))\n",
    "\n",
    "    # Only at the beginning we compare previous and current frame\n",
    "    \n",
    "    resultsTracker=tracker.update(detections)\n",
    "    \n",
    "    for result in resultsTracker:\n",
    "        x1,y1,x2,y2,Id = result\n",
    "        cx = int((x1+x2) / 2)\n",
    "        cy = int((y1+y2) / 2)\n",
    "        Id = int(Id)\n",
    "                \n",
    "    # for object_id, pt in tracking_objects.items():\n",
    "        if dist((cx,cy), L1_A, L1_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'L1')\n",
    "        \n",
    "        elif dist((cx,cy), L2_A, L2_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'L2')\n",
    "            \n",
    "        elif dist((cx,cy), L3_A, L3_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'L3')\n",
    "        \n",
    "        elif dist((cx,cy), L4_A, L4_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'L4')\n",
    "            \n",
    "            \n",
    "        elif dist((cx,cy), R1_A, R1_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'R1')\n",
    "        \n",
    "        elif dist((cx,cy), R2_A, R2_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'R2')\n",
    "            \n",
    "        elif dist((cx,cy), R3_A, R3_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'R3')\n",
    "        \n",
    "        elif dist((cx,cy), R4_A, R4_B) < 30:\n",
    "            tracking_objects[Id]=(cx,cy,'R4')\n",
    "        \n",
    "        else:\n",
    "            tracking_objects[Id]=(cx,cy,'Danger')\n",
    "            if Id in danger_car_pt:\n",
    "                danger_car_pt[Id] +=1\n",
    "                if danger_car_pt[Id] > 30 and id not in danger_car_id:\n",
    "                    danger_car_id.append(Id)\n",
    "                    \n",
    "            else:\n",
    "                danger_car_pt[Id] = 1\n",
    "\n",
    "    for object_id, pt in tracking_objects.items():\n",
    "        tmp= pt[2]+'['+str(object_id)+']'\n",
    "        cv2.circle(frame, (pt[0],pt[1]), 5, (0, 0, 255), -1)\n",
    "        cv2.putText(frame, tmp, (pt[0], pt[1] - 7), 0, 0.8, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    center_points_prev_frame = [center_points_cur_frame.copy()]\n",
    "    print(danger_car_id)\n",
    "    print(danger_car_pt)\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from object_detection import ObjectDetection\n",
    "import math\n",
    "# from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import *\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = 'mmask.png'\n",
    "\n",
    "# 이미지 열기\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# 이미지 플로팅\n",
    "plt.imshow(img)\n",
    "\n",
    "# 점 좌표 (예시)\n",
    "point_x = 100\n",
    "point_y = 150\n",
    "\n",
    "pooint_x = 130\n",
    "pooint_y = 150\n",
    "\n",
    "# 점 그리기\n",
    "plt.scatter(point_x, point_y, c='red', marker='o', s=50)  # 점 색상, 모양, 크기 등 설정\n",
    "plt.scatter(pooint_x, pooint_y, c='blue', marker='o', s=50)  # 점 색상, 모양, 크기 등 설정\n",
    "\n",
    "# 플로팅 업데이트\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from object_detection import ObjectDetection\n",
    "import math\n",
    "from sort import *\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "def dist(P, A, B):\n",
    "    area = abs ( (A[0] - P[0]) * (B[1] - P[1]) - (A[1] - P[1]) * (B[0] - P[0]) )\n",
    "    AB = ( (A[0] - B[0]) ** 2 + (A[1] - B[1]) ** 2 ) ** 0.5\n",
    "    return ( area / AB )\n",
    "\n",
    "f1_A=(388,821)\n",
    "f1_B=(661,404) #distance 40\n",
    "\n",
    "f2_A=(582, 876) #id 194\n",
    "f2_B=(703, 415) #id 91 distance 30\n",
    "\n",
    "f3_A=(782, 865) #id 60\n",
    "f3_B=(743, 417) #id 30  distance 30\n",
    "\n",
    "f4_A=(999, 866) #id 105\n",
    "f4_B=(789, 417)  #id 85  distacne 30\n",
    "\n",
    "f5_A=(1183, 850) #id 4\n",
    "f5_B=(846, 429) #id 29 distance 30\n",
    "\n",
    "# Initialize Object Detection\n",
    "# od = ObjectDetection()\n",
    "model = YOLO('yolov8n.pt')\n",
    "cap = cv2.VideoCapture(\"2.mp4\")\n",
    "\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\t# 영상의 넓이(가로) 프레임\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\t# 영상의 높이(세로) 프레임\n",
    "frame_size = (frameWidth, frameHeight)\n",
    "\n",
    "print(frame_size)\n",
    "# Initialize count\n",
    "count = 0\n",
    "center_points_prev_frame = []\n",
    "\n",
    "danger_car_id=[]\n",
    "\n",
    "tracking_objects = {}\n",
    "track_id = 0\n",
    "\n",
    "tracker = Sort(max_age=10, min_hits=3, iou_threshold=0.3)\n",
    "mask = cv2.imread(\"mask.png\")\n",
    "\n",
    "while True:\n",
    "    retval, frame = cap.read()\n",
    "    # imgRegion = cv2.bitwise_and(frame,mask)\n",
    "    count += 1\n",
    "    if not(retval):\n",
    "        break\n",
    "\n",
    "    # Point current frame\n",
    "    center_points_cur_frame = []\n",
    "\n",
    "    # Detect objects on frame\n",
    "    results = model(frame,stream=True)\n",
    "    detections = np.empty((0,5))\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cx = int((x1+x2) / 2)\n",
    "            cy = int((y1+y2) / 2)\n",
    "            center_points_cur_frame.append((cx, cy, 'Danger!'))\n",
    "            conf = math.ceil((box.conf[0]*100)) / 100\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    "            #print(\"FRAME N°\", count, \" \", x, y, w, h)\n",
    "            # cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "            if currentClass == \"car\" or currentClass == \"truck\" or currentClass == \"bus\" \\\n",
    "                    or currentClass == \"motorbike\" or currentClass == \"person\" and conf > 0.3:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2,y2), (0, 255, 0), 2) \n",
    "                currentArray = np.array([x1,y1,x2,y2,conf])\n",
    "                detections = np.vstack((detections,currentArray))\n",
    "\n",
    "    # Only at the beginning we compare previous and current frame\n",
    "    \n",
    "\n",
    "    resultsTracker=tracker.update(detections)\n",
    "    \n",
    "    for result in resultsTracker:\n",
    "        x1,y1,x2,y2,Id = result\n",
    "        cx = int((x1+x2) / 2)\n",
    "        cy = int((y1+y2) / 2)\n",
    "        Id = int(Id)\n",
    "        # print(cx,cy,Id)\n",
    "                \n",
    "    # for object_id, pt in tracking_objects.items():\n",
    "        # if dist((cx,cy), f1_A, f1_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f1')\n",
    "        \n",
    "        # elif dist((cx,cy), f2_A, f2_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f2')\n",
    "            \n",
    "        # elif dist((cx,cy), f3_A, f3_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f3')\n",
    "        \n",
    "        # elif dist((cx,cy), f4_A, f4_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f4')\n",
    "        \n",
    "        # elif dist((cx,cy), f5_A, f5_B) < 30:\n",
    "        #     tracking_objects[Id]=(cx,cy,'f5')\n",
    "        \n",
    "        # else:\n",
    "        #     tracking_objects[Id]=(cx,cy,'Danger!')\n",
    "        \n",
    "            \n",
    "            \n",
    "    # for object_id, pt in tracking_objects.items():\n",
    "    #     tmp= pt[2]+'['+str(object_id)+']'\n",
    "    #     cv2.circle(frame, (pt[0],pt[1]), 5, (0, 0, 255), -1)\n",
    "    #     cv2.putText(frame, tmp, (pt[0], pt[1] - 7), 0, 0.8, (0, 0, 255), 2)\n",
    "        \n",
    "    #     if (pt[2]=='Danger!'):\n",
    "    #         danger_car_id.append(object_id)\n",
    "            \n",
    "                \n",
    "    \n",
    "    \n",
    "\n",
    "    # print(\"Tracking objects\")\n",
    "    # # print(tracking_objects)\n",
    "\n",
    "\n",
    "    # print(\"CUR FRAME LEFT PTS\")\n",
    "    # print(center_points_cur_frame)\n",
    "    \n",
    "#     cv2.circle(frame, (1,1), 5, (0, 0, 255), -1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    # cv2.imshow(\"ImageFrame\",imgRegion)\n",
    "    # Make a copy of the points\n",
    "    center_points_prev_frame = center_points_cur_frame.copy()\n",
    "\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
